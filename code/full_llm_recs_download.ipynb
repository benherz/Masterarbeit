{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a32af7d8",
   "metadata": {},
   "source": [
    "### LLM recommendations notebook\n",
    "\n",
    "In this notebook, I will use the downloaded and slightly preprocessed financial statmements of ~1490 companies to obtain buy/sell/hold recommendations of Google's Gemini-2.5-flash model. \n",
    "\n",
    "Overall, three functions are employed:\n",
    "- get_llm_ratings(): For a given CIK, this function loops over dates, grabbing the respective financial statements and parses it together in a format that can be input to a LLM.\n",
    "- get_llm_ratings_with_previous_quarters(): Very similar to the above function, but it additionally selects financial statements from previous quartes, belonging to the CIK. \n",
    "- llm_ratings_loop(): This function simply loops over an input list of CIKs, repeatedly calls one of the above functions and neatly concatenates and saves the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e7b1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from google.genai.errors import ServerError  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7bdf7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gemini API key\n",
    "with open(\"../proton_google_api_key.txt\", \"r\") as f:\n",
    "    key = f.read().strip()    \n",
    "\n",
    "# Initialize the Gemini client with the API key\n",
    "client = genai.Client(api_key = key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404b632",
   "metadata": {},
   "source": [
    "- Read in financial statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12b0b380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_23896\\2672417944.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  labeled_income_statements = pd.read_csv(\"../data/income_statements_with_labels.csv\", dtype={\"CIK\": str})\n",
      "C:\\Users\\benny\\AppData\\Local\\Temp\\ipykernel_23896\\2672417944.py:3: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  labeled_cash_flow_statements = pd.read_csv(\"../data/cash_flow_statements_with_labels.csv\", dtype={\"CIK\": str})\n"
     ]
    }
   ],
   "source": [
    "labeled_balance_sheets = pd.read_csv(\"../data/balance_sheets_with_labels.csv\", dtype={\"CIK\": str})\n",
    "labeled_income_statements = pd.read_csv(\"../data/income_statements_with_labels.csv\", dtype={\"CIK\": str})\n",
    "labeled_cash_flow_statements = pd.read_csv(\"../data/cash_flow_statements_with_labels.csv\", dtype={\"CIK\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fae200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Minor validity check\n",
    "bs_uniques = labeled_balance_sheets[\"CIK\"].unique()\n",
    "is_uniques = labeled_income_statements[\"CIK\"].unique()\n",
    "cs_uniques = labeled_cash_flow_statements[\"CIK\"].unique()\n",
    "\n",
    "# Find overlap \n",
    "ciks = set(bs_uniques) & set(is_uniques) & set(cs_uniques)\n",
    "len(ciks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cf5b016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the set to a DataFrame\n",
    "cik_df = pd.DataFrame(list(ciks), columns=[\"CIK\"])\n",
    "ciks1 = cik_df.iloc[:500]\n",
    "ciks2 = cik_df.iloc[500:1000]\n",
    "ciks3 = cik_df.iloc[1000:]\n",
    "len(ciks1) + len(ciks2) + len(ciks3) == len(ciks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d9adeca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cik",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "rating",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "6d682ef3-6d13-4732-a4a3-8eb5452ec3d3",
       "rows": [
        [
         "0",
         "0001497645",
         "2010-03-31",
         "sell"
        ],
        [
         "1",
         "0001497645",
         "2010-06-30",
         "sell"
        ],
        [
         "2",
         "0001497645",
         "2010-09-30",
         "sell"
        ],
        [
         "3",
         "0001497645",
         "2010-12-31",
         "sell"
        ],
        [
         "4",
         "0001497645",
         "2011-03-31",
         "sell"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cik</th>\n",
       "      <th>date</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001497645</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001497645</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001497645</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001497645</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001497645</td>\n",
       "      <td>2011-03-31</td>\n",
       "      <td>sell</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cik        date rating\n",
       "0  0001497645  2010-03-31   sell\n",
       "1  0001497645  2010-06-30   sell\n",
       "2  0001497645  2010-09-30   sell\n",
       "3  0001497645  2010-12-31   sell\n",
       "4  0001497645  2011-03-31   sell"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LLM recommendations with only most recent financial statements\n",
    "llm_recommendations1 = pd.read_csv(\"../data/ciklist1_ratings_with_most_recent_quarters.csv\", dtype={\"cik\": str})\n",
    "llm_recommendations2 = pd.read_csv(\"../data/ciklist2_ratings_with_most_recent_quarters.csv\", dtype={\"cik\": str})\n",
    "llm_recommendations3 = pd.read_csv(\"../data/ciklist3_ratings_with_most_recent_quarters.csv\", dtype={\"cik\": str})\n",
    "\n",
    "# Combine into one DataFrame\n",
    "llm_recommendations = pd.concat([llm_recommendations1, llm_recommendations2, llm_recommendations3], ignore_index=True)\n",
    "llm_recommendations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c13edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_ciks = set(llm_recommendations[\"cik\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b12bda00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0000002969',\n",
       " '0000004962',\n",
       " '0000005272',\n",
       " '0000008818',\n",
       " '0000008858',\n",
       " '0000009092',\n",
       " '0000012927',\n",
       " '0000014930',\n",
       " '0000015615',\n",
       " '0000016160',\n",
       " '0000020520',\n",
       " '0000021076',\n",
       " '0000021344',\n",
       " '0000021535',\n",
       " '0000021665',\n",
       " '0000022356',\n",
       " '0000022444',\n",
       " '0000024741',\n",
       " '0000025232',\n",
       " '0000026324',\n",
       " '0000027419',\n",
       " '0000029002',\n",
       " '0000029644',\n",
       " '0000029905',\n",
       " '0000030697',\n",
       " '0000031791',\n",
       " '0000036104',\n",
       " '0000038725',\n",
       " '0000038777',\n",
       " '0000040533',\n",
       " '0000040704',\n",
       " '0000040729',\n",
       " '0000040987',\n",
       " '0000045012',\n",
       " '0000047217',\n",
       " '0000049826',\n",
       " '0000051143',\n",
       " '0000051434',\n",
       " '0000056047',\n",
       " '0000056978',\n",
       " '0000062709',\n",
       " '0000066382',\n",
       " '0000069891',\n",
       " '0000070318',\n",
       " '0000070866',\n",
       " '0000072331',\n",
       " '0000072741',\n",
       " '0000074260',\n",
       " '0000076605',\n",
       " '0000077360',\n",
       " '0000078890',\n",
       " '0000080172',\n",
       " '0000080424',\n",
       " '0000084748',\n",
       " '0000084839',\n",
       " '0000085961',\n",
       " '0000087347',\n",
       " '0000090498',\n",
       " '0000090896',\n",
       " '0000091142',\n",
       " '0000092122',\n",
       " '0000096943',\n",
       " '0000098362',\n",
       " '0000098677',\n",
       " '0000099780',\n",
       " '0000104169',\n",
       " '0000104889',\n",
       " '0000105634',\n",
       " '0000107140',\n",
       " '0000107263',\n",
       " '0000202058',\n",
       " '0000275880',\n",
       " '0000315189',\n",
       " '0000317540',\n",
       " '0000318154',\n",
       " '0000320187',\n",
       " '0000320335',\n",
       " '0000351569',\n",
       " '0000352541',\n",
       " '0000354963',\n",
       " '0000701985',\n",
       " '0000703351',\n",
       " '0000707179',\n",
       " '0000714310',\n",
       " '0000718937',\n",
       " '0000719955',\n",
       " '0000721994',\n",
       " '0000723531',\n",
       " '0000729986',\n",
       " '0000730263',\n",
       " '0000749251',\n",
       " '0000751978',\n",
       " '0000755001',\n",
       " '0000764065',\n",
       " '0000764401',\n",
       " '0000764622',\n",
       " '0000766704',\n",
       " '0000766829',\n",
       " '0000790051',\n",
       " '0000795266',\n",
       " '0000795403',\n",
       " '0000797468',\n",
       " '0000799233',\n",
       " '0000805676',\n",
       " '0000812011',\n",
       " '0000816956',\n",
       " '0000821189',\n",
       " '0000821483',\n",
       " '0000822416',\n",
       " '0000827052',\n",
       " '0000832101',\n",
       " '0000840489',\n",
       " '0000846617',\n",
       " '0000851968',\n",
       " '0000857855',\n",
       " '0000858877',\n",
       " '0000860748',\n",
       " '0000866729',\n",
       " '0000866829',\n",
       " '0000868780',\n",
       " '0000873303',\n",
       " '0000877212',\n",
       " '0000877422',\n",
       " '0000879169',\n",
       " '0000882184',\n",
       " '0000884219',\n",
       " '0000885245',\n",
       " '0000885978',\n",
       " '0000886346',\n",
       " '0000887343',\n",
       " '0000887905',\n",
       " '0000887936',\n",
       " '0000889331',\n",
       " '0000891014',\n",
       " '0000892553',\n",
       " '0000893538',\n",
       " '0000895126',\n",
       " '0000895447',\n",
       " '0000896159',\n",
       " '0000899751',\n",
       " '0000906553',\n",
       " '0000908255',\n",
       " '0000912615',\n",
       " '0000912728',\n",
       " '0000912767',\n",
       " '0000914156',\n",
       " '0000916076',\n",
       " '0000916789',\n",
       " '0000920522',\n",
       " '0000924901',\n",
       " '0000926326',\n",
       " '0000943452',\n",
       " '0000947484',\n",
       " '0000949870',\n",
       " '0001001250',\n",
       " '0001001316',\n",
       " '0001002910',\n",
       " '0001003078',\n",
       " '0001004980',\n",
       " '0001005817',\n",
       " '0001012019',\n",
       " '0001013934',\n",
       " '0001018840',\n",
       " '0001020569',\n",
       " '0001021860',\n",
       " '0001023024',\n",
       " '0001024305',\n",
       " '0001029142',\n",
       " '0001030469',\n",
       " '0001031296',\n",
       " '0001034054',\n",
       " '0001035201',\n",
       " '0001038074',\n",
       " '0001040829',\n",
       " '0001046257',\n",
       " '0001046311',\n",
       " '0001048695',\n",
       " '0001048911',\n",
       " '0001050377',\n",
       " '0001050797',\n",
       " '0001054905',\n",
       " '0001056288',\n",
       " '0001057060',\n",
       " '0001060391',\n",
       " '0001062231',\n",
       " '0001065696',\n",
       " '0001068851',\n",
       " '0001069258',\n",
       " '0001069878',\n",
       " '0001069899',\n",
       " '0001070985',\n",
       " '0001071255',\n",
       " '0001077428',\n",
       " '0001078271',\n",
       " '0001084048',\n",
       " '0001090012',\n",
       " '0001094285',\n",
       " '0001097149',\n",
       " '0001103982',\n",
       " '0001108134',\n",
       " '0001117297',\n",
       " '0001121788',\n",
       " '0001126328',\n",
       " '0001130310',\n",
       " '0001137789',\n",
       " '0001138118',\n",
       " '0001140859',\n",
       " '0001144980',\n",
       " '0001158895',\n",
       " '0001166003',\n",
       " '0001170010',\n",
       " '0001230245',\n",
       " '0001237831',\n",
       " '0001265131',\n",
       " '0001267238',\n",
       " '0001267565',\n",
       " '0001278027',\n",
       " '0001285785',\n",
       " '0001286043',\n",
       " '0001289490',\n",
       " '0001295810',\n",
       " '0001297989',\n",
       " '0001299939',\n",
       " '0001316835',\n",
       " '0001324404',\n",
       " '0001331875',\n",
       " '0001350593',\n",
       " '0001356576',\n",
       " '0001364250',\n",
       " '0001370637',\n",
       " '0001373670',\n",
       " '0001373715',\n",
       " '0001374310',\n",
       " '0001396009',\n",
       " '0001397187',\n",
       " '0001398659',\n",
       " '0001400810',\n",
       " '0001402057',\n",
       " '0001404912',\n",
       " '0001428205',\n",
       " '0001430723',\n",
       " '0001433195',\n",
       " '0001433270',\n",
       " '0001434588',\n",
       " '0001439288',\n",
       " '0001448893',\n",
       " '0001476204',\n",
       " '0001479094',\n",
       " '0001500217',\n",
       " '0001516513',\n",
       " '0001517175',\n",
       " '0001517302',\n",
       " '0001519751',\n",
       " '0001521332',\n",
       " '0001527590',\n",
       " '0001528396',\n",
       " '0001530721',\n",
       " '0001532961',\n",
       " '0001535527',\n",
       " '0001537054',\n",
       " '0001539838',\n",
       " '0001551152',\n",
       " '0001559720',\n",
       " '0001559865',\n",
       " '0001562401',\n",
       " '0001564708',\n",
       " '0001567094',\n",
       " '0001569187',\n",
       " '0001571283',\n",
       " '0001571996',\n",
       " '0001576940',\n",
       " '0001577916',\n",
       " '0001578732',\n",
       " '0001579091',\n",
       " '0001580905',\n",
       " '0001590717',\n",
       " '0001592386',\n",
       " '0001596993',\n",
       " '0001597033',\n",
       " '0001598428',\n",
       " '0001601046',\n",
       " '0001606498',\n",
       " '0001609711',\n",
       " '0001618921',\n",
       " '0001624794',\n",
       " '0001632127',\n",
       " '0001635088',\n",
       " '0001636519',\n",
       " '0001637459',\n",
       " '0001649749',\n",
       " '0001650132',\n",
       " '0001666700',\n",
       " '0001673985',\n",
       " '0001679273',\n",
       " '0001679788',\n",
       " '0001691303',\n",
       " '0001711269',\n",
       " '0001718512',\n",
       " '0001739445',\n",
       " '0001748824',\n",
       " '0001751788',\n",
       " '0001755672',\n",
       " '0001757073',\n",
       " '0001759655',\n",
       " '0001781335',\n",
       " '0001783180',\n",
       " '0001794515',\n",
       " '0001794669',\n",
       " '0001811074',\n",
       " '0001822993',\n",
       " '0001823529',\n",
       " '0001845815',\n",
       " '0001849253',\n",
       " '0001856437',\n",
       " '0001867072',\n",
       " '0001958086',\n",
       " '0001968487',\n",
       " '0001968915'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_ciks = ciks - llm_ciks \n",
    "missing_ciks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7f59f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = {\"0000106640\", \"0001061983\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f49da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciks_with_errors = {\n",
    "    \"0001235468\",\n",
    "    \"0000723188\",\n",
    "    \"0000046080\",\n",
    "    \"0001020710\",\n",
    "    \"0000811589\",\n",
    "    \"0000051253\",\n",
    "    \"0000875320\",\n",
    "    \"0001013857\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdbb816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list(missing_ciks)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8441c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000106640', '0001061983']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any of failed downloads are in the missing CIKs\n",
    "failed_in_missing = [cik for cik in failed_download_ciks if cik in missing_ciks]\n",
    "failed_in_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79968f8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Functions to be used in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4213e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_ratings(cik: str, balance_sheets = None, income_statements = None, cash_flow_statements = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns a DataFrame with LLM ratings for a given CIK.\n",
    "    For every reporting date, the function fetches the most recent financial statements, i.e.\n",
    "    - Balance Sheet\n",
    "    - Cash Flow Statement\n",
    "    - Income Statement\n",
    "    and calls the LLM to get a buy/sell/hold recommendation. In order to avoid issues with reports that were filed slightly apart,\n",
    "    a window of 10 days around a given reporting date is used. This helps to ensure that the LLM has access to all relevant financial information for a given reporting date.\n",
    "    Furthermore, reports that were filed slightly apart will not lead to recommendations that are based on partial information only and will also not cause multiple\n",
    "    recommendations that only lie within the window of 10 days around a given reporting date.\n",
    "    \n",
    "    Parameters: \n",
    "    cik: str, CIK of the company (Can be looked up on the SEC website)\n",
    "    balance_sheets: Balance Sheets DataFrame with columns: STD Balance Sheet All, FCC Item Name, CIK and Date (among others)\n",
    "    income_statements: Income Statements DataFrame with columns: STD Income Statement All, FCC Item Name, CIK and Date (among others)\n",
    "    cash_flow_statements: Cash Flow Statements DataFrame with columns: STD Cash Flow All, FCC Item Name, CIK and Date (among others)\n",
    "    \"\"\"\n",
    "    \n",
    "    # First filter dfs for input CIK\n",
    "    balance_sheets = balance_sheets[balance_sheets[\"CIK\"] == cik].copy()\n",
    "    income_statements = income_statements[income_statements[\"CIK\"] == cik].copy()\n",
    "    cash_flow_statements = cash_flow_statements[cash_flow_statements[\"CIK\"] == cik].copy()\n",
    "    \n",
    "    # Convert the date columns to datetime objects\n",
    "    for df in [balance_sheets, income_statements, cash_flow_statements]:\n",
    "        df[\"Report Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Determine unique dates\n",
    "    reporting_dates = pd.concat([\n",
    "        balance_sheets[\"Report Date\"],\n",
    "        income_statements[\"Report Date\"],\n",
    "        cash_flow_statements[\"Report Date\"]\n",
    "    ]).unique()\n",
    "\n",
    "    # Sort dates just to be safe\n",
    "    reporting_dates = np.sort(reporting_dates)\n",
    "\n",
    "    # In order to handle reports, that were filed slighty apart, a window of 10 days around a given reporting date is used\n",
    "    window = pd.Timedelta(days=10)\n",
    "\n",
    "    # Loop over reporting dates to obtain LLM ratings\n",
    "    llm_ratings = []\n",
    "    for date in reporting_dates:\n",
    "\n",
    "        # Subset all financial statements for the given dates +- window days\n",
    "        # Current quarter\n",
    "        bs = balance_sheets[(balance_sheets[\"Report Date\"] >= date - window) & (balance_sheets[\"Report Date\"] <= date + window)]\n",
    "        is_ = income_statements[(income_statements[\"Report Date\"] >= date - window) & (income_statements[\"Report Date\"] <= date + window)]\n",
    "        cf = cash_flow_statements[(cash_flow_statements[\"Report Date\"] >= date - window) & (cash_flow_statements[\"Report Date\"] <= date + window)]\n",
    "\n",
    "        # If any of the DataFrames is empty, skip this date\n",
    "        if bs.empty or is_.empty or cf.empty:\n",
    "            continue\n",
    "\n",
    "        # Concatenate reports into a string with correct labels\n",
    "        bs_str = \"\\n\".join(bs.apply(lambda row: f\"{row['position_label']}: {row['STD Balance Sheet All']}\", axis=1).astype(str))\n",
    "        is_str = \"\\n\".join(is_.apply(lambda row: f\"{row['position_label']}: {row['STD Income Statement All']}\", axis=1).astype(str))\n",
    "        cf_str = \"\\n\".join(cf.apply(lambda row: f\"{row['position_label']}: {row['STD Cash Flow All']}\", axis=1).astype(str))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Call the LLM to get the rating\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-lite\", # \"gemini-2.5-flash\"\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0, # Deterministic ouput\n",
    "                system_instruction=\"\"\"You are an experienced, data-driven financial analyst, that provides concise and accurate answers.\"\"\",\n",
    "                \n",
    "                thinking_config=types.ThinkingConfig(thinking_budget=0),# Disables thinking, but only required for Gemini 2.5\n",
    "            ),\n",
    "            \n",
    "            contents=[f\"\"\"\n",
    "            Based on the following financial reports only, please provide an investment recommendation for the underlying company.\n",
    "                      \n",
    "            Balance Sheet: \n",
    "            {bs_str}\n",
    "\n",
    "            Income Statement: \n",
    "            {is_str}\n",
    "\n",
    "            Cash Flow Statement: \n",
    "            {cf_str}\n",
    "\n",
    "            Provide your answer using only one of the following signals: 'strong buy', 'buy', 'hold', 'sell', or 'strong sell'.\n",
    "            \"\"\"]\n",
    "        )\n",
    "\n",
    "        # Extract rating from the response\n",
    "        rating = response.text.strip().lower()\n",
    "        llm_ratings.append({\n",
    "            \"cik\": str(cik),  # Ensure CIK is a string\n",
    "            \"date\": date,\n",
    "            \"rating\": rating\n",
    "        })\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    llm_ratings_df = pd.DataFrame(llm_ratings)\n",
    "\n",
    "    # Convert Report Date to datetime\n",
    "    llm_ratings_df[\"date\"] = pd.to_datetime(llm_ratings_df[\"date\"]).dt.date\n",
    "\n",
    "    # Sort by Report Date\n",
    "    llm_ratings_df.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    llm_ratings_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return llm_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32289e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_ratings_with_previous_quarters(cik: str, balance_sheets = None, income_statements = None, cash_flow_statements = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that returns a DataFrame with LLM ratings for a given CIK.\n",
    "    For every reporting date, the function fetches the most recent financial statements, i.e.\n",
    "    - Balance Sheet\n",
    "    - Cash Flow Statement\n",
    "    - Income Statement\n",
    "    and calls the LLM to get a buy/sell/hold recommendation. In order to avoid issues with reports that were filed slightly apart,\n",
    "    a window of 10 days around a given reporting date is used. This helps to ensure that the LLM has access to all relevant financial information for a given reporting date.\n",
    "    Furthermore, reports that were filed slightly apart will not lead to recommendations that are based on partial information only and will also not cause multiple\n",
    "    recommendations that only lie within the window of 10 days around a given reporting date.\n",
    "    \n",
    "    Parameters: \n",
    "    cik: str, CIK of the company (Can be looked up on the SEC website)\n",
    "    balance_sheets: Balance Sheets DataFrame with columns: STD Balance Sheet All, FCC Item Name, CIK and Date (among others)\n",
    "    income_statements: Income Statements DataFrame with columns: STD Income Statement All, FCC Item Name, CIK and Date (among others)\n",
    "    cash_flow_statements: Cash Flow Statements DataFrame with columns: STD Cash Flow All, FCC Item Name, CIK and Date (among others)\n",
    "    \"\"\"\n",
    "    \n",
    "    # First filter dfs for input CIK\n",
    "    balance_sheets = balance_sheets[balance_sheets[\"CIK\"] == cik].copy()\n",
    "    income_statements = income_statements[income_statements[\"CIK\"] == cik].copy()\n",
    "    cash_flow_statements = cash_flow_statements[cash_flow_statements[\"CIK\"] == cik].copy()\n",
    "    \n",
    "    # Convert the date columns to datetime objects\n",
    "    for df in [balance_sheets, income_statements, cash_flow_statements]:\n",
    "        df[\"Report Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Determine unique dates\n",
    "    reporting_dates = pd.concat([\n",
    "        balance_sheets[\"Report Date\"],\n",
    "        income_statements[\"Report Date\"],\n",
    "        cash_flow_statements[\"Report Date\"]\n",
    "    ]).unique()\n",
    "\n",
    "    # Sort dates just to be safe\n",
    "    reporting_dates = np.sort(reporting_dates)\n",
    "\n",
    "    # In order to handle reports, that were filed slighty apart, a window of 10 days around a given reporting date is used\n",
    "    window = pd.Timedelta(days=10)\n",
    "\n",
    "    # Loop over reporting dates to obtain LLM ratings\n",
    "    llm_ratings = []\n",
    "    for i, date in enumerate(reporting_dates):\n",
    "\n",
    "\n",
    "        # Determine current date\n",
    "        q0_date = date\n",
    "        # Determine date of previous quarter\n",
    "        qminus1_date = date - pd.DateOffset(months=3)\n",
    "        # Determine date of q0 -2 \n",
    "        qminus2_date = date - pd.DateOffset(months=6)\n",
    "        # Determine date of q0 -3\n",
    "        qminus3_date = date - pd.DateOffset(months=9)        \n",
    "\n",
    "\n",
    "        # Subset all financial statements for the given dates +- window days\n",
    "        # Current quarter\n",
    "        bs = balance_sheets[\n",
    "            (balance_sheets[\"Report Date\"] >= date - window) &\n",
    "            (balance_sheets[\"Report Date\"] <= date + window)\n",
    "        ]\n",
    "        is_0 = income_statements[\n",
    "            (income_statements[\"Report Date\"] >= date - window) &\n",
    "            (income_statements[\"Report Date\"] <= date + window)\n",
    "        ]\n",
    "        cf_0 = cash_flow_statements[\n",
    "            (cash_flow_statements[\"Report Date\"] >= date - window) &\n",
    "            (cash_flow_statements[\"Report Date\"] <= date + window)\n",
    "        ]\n",
    "\n",
    "        # Previous quarter (Q-1)\n",
    "        is_qminus1 = income_statements[\n",
    "            (income_statements[\"Report Date\"] >= qminus1_date - window) &\n",
    "            (income_statements[\"Report Date\"] <= qminus1_date + window)\n",
    "        ]\n",
    "        cf_qminus1 = cash_flow_statements[\n",
    "            (cash_flow_statements[\"Report Date\"] >= qminus1_date - window) &\n",
    "            (cash_flow_statements[\"Report Date\"] <= qminus1_date + window)\n",
    "        ]\n",
    "\n",
    "        # Two quarters ago (Q-2)\n",
    "        is_qminus2 = income_statements[\n",
    "            (income_statements[\"Report Date\"] >= qminus2_date - window) &\n",
    "            (income_statements[\"Report Date\"] <= qminus2_date + window)\n",
    "        ]\n",
    "        cf_qminus2 = cash_flow_statements[\n",
    "            (cash_flow_statements[\"Report Date\"] >= qminus2_date - window) &\n",
    "            (cash_flow_statements[\"Report Date\"] <= qminus2_date + window)\n",
    "        ]\n",
    "\n",
    "        # Three quarters ago (Q-3)\n",
    "        is_qminus3 = income_statements[\n",
    "            (income_statements[\"Report Date\"] >= qminus3_date - window) &\n",
    "            (income_statements[\"Report Date\"] <= qminus3_date + window)\n",
    "        ]\n",
    "        cf_qminus3 = cash_flow_statements[\n",
    "            (cash_flow_statements[\"Report Date\"] >= qminus3_date - window) &\n",
    "            (cash_flow_statements[\"Report Date\"] <= qminus3_date + window)\n",
    "        ]\n",
    "\n",
    "        # If no reports are available for the given date, skip to next date\n",
    "        if bs.empty or is_0.empty or cf_0.empty:\n",
    "            print(f\"No reports available for date {date}. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Concatenate reports into strings with correct labels\n",
    "        bs_str = \"\\n\".join(bs.apply(lambda row: f\"{row['position_label']}: {row['STD Balance Sheet All']}\", axis=1).astype(str))\n",
    "        is_str = \"\\n\".join(is_0.apply(lambda row: f\"{row['position_label']}: {row['STD Income Statement All']}\", axis=1).astype(str))\n",
    "        cf_str = \"\\n\".join(cf_0.apply(lambda row: f\"{row['position_label']}: {row['STD Cash Flow All']}\", axis=1).astype(str))\n",
    "\n",
    "        # Append previous quarters if available â€” even if just one of IS or CF is present\n",
    "        if not is_qminus1.empty:\n",
    "            is_qminus1_str = \"\\n\".join(is_qminus1.apply(lambda row: f\"{row['position_label']}: {row['STD Income Statement All']}\", axis=1).astype(str))\n",
    "            is_str += f\"\\n\\nIncome Statement from previous quarter:\\n{is_qminus1_str}\"\n",
    "        if not cf_qminus1.empty:\n",
    "            cf_qminus1_str = \"\\n\".join(cf_qminus1.apply(lambda row: f\"{row['position_label']}: {row['STD Cash Flow All']}\", axis=1).astype(str))\n",
    "            cf_str += f\"\\n\\nCash Flow Statement from previous quarter:\\n{cf_qminus1_str}\"\n",
    "\n",
    "        if not is_qminus2.empty:\n",
    "            is_qminus2_str = \"\\n\".join(is_qminus2.apply(lambda row: f\"{row['position_label']}: {row['STD Income Statement All']}\", axis=1).astype(str))\n",
    "            is_str += f\"\\n\\nIncome Statement from two quarters ago:\\n{is_qminus2_str}\"\n",
    "        if not cf_qminus2.empty:\n",
    "            cf_qminus2_str = \"\\n\".join(cf_qminus2.apply(lambda row: f\"{row['position_label']}: {row['STD Cash Flow All']}\", axis=1).astype(str))\n",
    "            cf_str += f\"\\n\\nCash Flow Statement from two quarters ago:\\n{cf_qminus2_str}\"\n",
    "\n",
    "        if not is_qminus3.empty:\n",
    "            is_qminus3_str = \"\\n\".join(is_qminus3.apply(lambda row: f\"{row['position_label']}: {row['STD Income Statement All']}\", axis=1).astype(str))\n",
    "            is_str += f\"\\n\\nIncome Statement from three quarters ago:\\n{is_qminus3_str}\"\n",
    "        if not cf_qminus3.empty:\n",
    "            cf_qminus3_str = \"\\n\".join(cf_qminus3.apply(lambda row: f\"{row['position_label']}: {row['STD Cash Flow All']}\", axis=1).astype(str))\n",
    "            cf_str += f\"\\n\\nCash Flow Statement from three quarters ago:\\n{cf_qminus3_str}\"\n",
    "            \n",
    "\n",
    "        # Call the LLM to get the rating\n",
    "        response = client.models.generate_content(\n",
    "           # model=\"gemini-2.5-flash\", \n",
    "            model=\"gemini-2.5-flash-lite\",\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0, # Deterministic ouput\n",
    "                system_instruction=\"\"\"You are an experienced, data-driven financial analyst, that provides concise and accurate answers.\"\"\",\n",
    "                \n",
    "                thinking_config=types.ThinkingConfig(thinking_budget=0),# Disables thinking, but only required for Gemini 2.5\n",
    "            ),\n",
    "            \n",
    "            contents=[f\"\"\"\n",
    "            Based on the following financial reports only, please provide an investment recommendation for the underlying company.\n",
    "                      \n",
    "            Balance Sheet: \n",
    "            {bs_str}\n",
    "\n",
    "            Income Statement: \n",
    "            {is_str}\n",
    "\n",
    "            Cash Flow Statement: \n",
    "            {cf_str}\n",
    "\n",
    "            Provide your answer using only one of the following signals: 'buy', 'hold' or 'sell'.\n",
    "            \"\"\"]\n",
    "        )\n",
    "\n",
    "        # Extract rating from the response\n",
    "        rating = response.text.strip().lower()\n",
    "        llm_ratings.append({\n",
    "            \"cik\": str(cik), \n",
    "            \"date\": date,\n",
    "            \"rating\": rating\n",
    "        })\n",
    "\n",
    "    # If no ratings were generated, return None\n",
    "    if not llm_ratings:\n",
    "        return None\n",
    "    \n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    llm_ratings_df = pd.DataFrame(llm_ratings)\n",
    "\n",
    "    llm_ratings_df[\"date\"] = pd.to_datetime(llm_ratings_df[\"date\"]).dt.date\n",
    "\n",
    "    # Sort by Report Date\n",
    "    llm_ratings_df.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "    # Reset index\n",
    "    llm_ratings_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return llm_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_ratings_loop(\n",
    "    cik_list,\n",
    "    balance_sheets,\n",
    "    income_statements,\n",
    "    cash_flow_statements,\n",
    "    function_to_use,\n",
    "    output_path_ratings=\"../data/ciklist1_ratings_with_previous_quarters.csv\",\n",
    "    output_path_failed=\"../data/failed_ciks1.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30\n",
    "):\n",
    "    \"\"\"\n",
    "    Process a list of CIKs to retrieve LLM ratings with retry logic on server errors.\n",
    "\n",
    "    Args:\n",
    "        cik_list (pd.DataFrame): DataFrame with a \"CIK\" column.\n",
    "        balance_sheets (dict or DataFrame): Balance sheet data.\n",
    "        income_statements (dict or DataFrame): Income statement data.\n",
    "        cash_flow_statements (dict or DataFrame): Cash flow data.\n",
    "        function_to_use (callable): Function to call for each CIK. (Either get_llm_ratings_with_previous_quarters or get_llm_ratings)\n",
    "        output_path_ratings (str): File path to save ratings CSV.\n",
    "        output_path_failed (str): File path to save failed CIKs.\n",
    "        retries (int): Number of retry attempts on server error.\n",
    "        retry_delay (int): Seconds to wait between retries.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined ratings DataFrame.\n",
    "    \"\"\"\n",
    "    list_ratings = []\n",
    "    failed_ciks = []\n",
    "    progress_bar = tqdm(cik_list[\"CIK\"], desc=\"Processing CIKs\")\n",
    "\n",
    "    for i, cik in enumerate(progress_bar):\n",
    "        progress_bar.set_description(\n",
    "            f\"Processing CIK {i+1}/{len(cik_list)}: {cik} | Time: {pd.Timestamp.now().strftime('%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                ratings = function_to_use(\n",
    "                    cik,\n",
    "                    balance_sheets,\n",
    "                    income_statements,\n",
    "                    cash_flow_statements\n",
    "                )\n",
    "                if ratings is not None:\n",
    "                    list_ratings.append(ratings)\n",
    "                break  # success, exit retry loop which starts at for attempt in range(retries)\n",
    "\n",
    "            except ServerError as e:\n",
    "                print(f\"ServerError for CIK {cik} (Attempt {attempt + 1}/{retries}): {e}\")\n",
    "                if attempt < retries - 1:\n",
    "                    time.sleep(retry_delay)\n",
    "                else: # This else statement basically only runs if all retries failed i.e. the inner loop is completed, hence it starts with the next CIK\n",
    "                    failed_ciks.append(cik)\n",
    "\n",
    "    # Save results to CSV\n",
    "    cik_ratings_df = pd.concat(list_ratings, ignore_index=True)\n",
    "    cik_ratings_df.to_csv(output_path_ratings, index=False)\n",
    "\n",
    "    # Save failed CIKs to CSV\n",
    "    if failed_ciks:\n",
    "        pd.Series(failed_ciks).to_csv(output_path_failed, index=False)\n",
    "\n",
    "    return cik_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fddcd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Downloading recommendations, including only most recent financial statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings1 = llm_ratings_loop(\n",
    "    cik_list=ciks1,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist1_ratings.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks1.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ca877",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2 = llm_ratings_loop(\n",
    "    cik_list=ciks2,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist2_ratings.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks2.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f035f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings3 = llm_ratings_loop(\n",
    "    cik_list=ciks3,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist3_ratings.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks3.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59da28",
   "metadata": {},
   "source": [
    "---\n",
    "### Downloading recommendations, including financial data from previous quartes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3eb51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_w_prev_quarters1 = llm_ratings_loop(\n",
    "    cik_list=ciks1,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist1_ratings_w_prev_quarters.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks1_w_prev_quarters.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecf174",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_w_prev_quarters2 = llm_ratings_loop(\n",
    "    cik_list=ciks2,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist2_ratings_w_prev_quarters.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks2_w_prev_quarters.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ac41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_w_prev_quarters3 = llm_ratings_loop(\n",
    "    cik_list=ciks3,\n",
    "    balance_sheets=labeled_balance_sheets,\n",
    "    income_statements=labeled_income_statements,\n",
    "    cash_flow_statements=labeled_cash_flow_statements,\n",
    "    function_to_use=get_llm_ratings,\n",
    "    output_path_ratings=\"../data/new_llm_ratings/ciklist3_ratings_w_prev_quarters.csv\",\n",
    "    output_path_failed=\"../data/new_llm_ratings/failed_ciks3_w_prev_quarters.csv\",\n",
    "    retries=5,\n",
    "    retry_delay=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
